{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6cc56f0def6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c07872ff0ce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_image.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('test_image.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_show(img):\n",
    "    cv2.imshow('image',img)\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_img=np.copy(img)\n",
    "gray=cv2.cvtColor(lane_img,cv2.COLOR_RGB2GRAY)# convert image ot gray scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing noise using gaussian blur\n",
    "blur=cv2.GaussianBlur(gray,(5,5),0)\n",
    "img_show(blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny=cv2.Canny(blur,50,150)  #50 is lower thresh and 150 is higher thresh\n",
    "img_show(canny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img):\n",
    "    height=img.shape[0] \n",
    "    triangle=np.array([[(200,height),(1150,height),(550,250)]])   # list of triangle coordinates as our ROI\n",
    "    mask=np.zeros_like(img)\n",
    "    cv2.fillPoly(mask,triangle,255)\n",
    "    masked_img=cv2.bitwise_and(img,mask)\n",
    "    return masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_img=region_of_interest(canny)\n",
    "img_show(region_of_interest(canny))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hough  Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_lines(img,lines):\n",
    "    line_img=np.zeros_like(img)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1,y1,x2,y2=line.reshape(4)\n",
    "            cv2.line(line_img,(x1,y1),(x2,y2),(0,255,0),10)\n",
    "        return line_img\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[660 373 754 467]]\n",
      "\n",
      " [[747 472 927 658]]\n",
      "\n",
      " [[320 703 378 607]]\n",
      "\n",
      " [[900 613 976 689]]\n",
      "\n",
      " [[617 333 695 414]]\n",
      "\n",
      " [[592 304 704 416]]\n",
      "\n",
      " [[321 701 445 494]]\n",
      "\n",
      " [[704 418 927 641]]\n",
      "\n",
      " [[402 541 455 460]]\n",
      "\n",
      " [[704 426 766 490]]]\n"
     ]
    }
   ],
   "source": [
    "lines = cv2.HoughLinesP(masked_img,rho = 2,theta = 1*np.pi/180,threshold = 100,minLineLength = 60,maxLineGap = 5)   #hough lines for line detection and 2nd and 3rd arg are the bin size of x and y axis 4th arg is threshhold i.e min number of votes needed to accept a bin\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 4)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending lines and original image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_img=display_lines(lane_img,lines)\n",
    "img_show(line_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_img=cv2.bitwise_or(line_img,img)\n",
    "img_show(comb_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_coordinates(img,params):\n",
    "    slope,intercept=params\n",
    "    y1=img.shape[0]\n",
    "    y2=420\n",
    "    x1=int((y1-intercept)/slope)\n",
    "    x2=int((x1+ (y2-y1)/slope))\n",
    "    return np.array([x1,y1,x2,y2])  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_slope_intercept(img,lines):\n",
    "    left_fit=[]\n",
    "    right_fit=[]\n",
    "    for line in lines:\n",
    "        x1,y1,x2,y2=line.reshape(4)\n",
    "        x=np.array([x1,x2])\n",
    "        y=np.array([y1,y2])\n",
    "        param=np.polyfit(x,y,1)\n",
    "        slope=param[0]\n",
    "        intercept=param[1]\n",
    "        if slope < 0:\n",
    "            left_fit.append((slope,intercept))\n",
    "        else:\n",
    "            right_fit.append((slope,intercept))\n",
    "    left_fit_avg=np.average(left_fit,axis=0)\n",
    "    right_fit_avg=np.average(right_fit,axis=0)\n",
    "    left_line=make_coordinates(img,left_fit_avg)\n",
    "    right_line=make_coordinates(img,right_fit_avg)\n",
    "    return np.array([left_line,right_line])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[311 704 486 420]\n",
      " [983 704 703 420]]\n"
     ]
    }
   ],
   "source": [
    "avg_lines=avg_slope_intercept(lane_img,lines)\n",
    "print(avg_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_img=display_lines(lane_img,avg_lines)\n",
    "\n",
    "comb_img=cv2.bitwise_or(line_img,img)\n",
    "img_show(comb_img) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Lane in a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3fc73e9e9b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test2.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlane_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture('test2.mp4')\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    _,frame=cap.read() \n",
    "    lane_img=np.copy(frame)\n",
    "    gray=cv2.cvtColor(lane_img,cv2.COLOR_RGB2GRAY)\n",
    "    blur=cv2.GaussianBlur(gray,(5,5),0)\n",
    "    canny=cv2.Canny(blur,50,150)\n",
    "    masked_img=region_of_interest(canny)\n",
    "    lines = cv2.HoughLinesP(masked_img,rho = 2,theta = 1*np.pi/180,threshold = 100,minLineLength = 60,maxLineGap = 5)   #hough lines for line detection and 2nd and 3rd arg are the bin size of x and y axis 4th arg is threshhold i.e min number of votes needed to accept a bin\n",
    "    avg_lines=avg_slope_intercept(lane_img,lines)\n",
    "    line_img=display_lines(lane_img,avg_lines)\n",
    "    comb_img=cv2.bitwise_or(line_img,lane_img)\n",
    "    img_show(comb_img)\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
